# Logstash Configuration for DevSecOps Application
input {
  # HTTP input for application logs
  http {
    host => "0.0.0.0"
    port => 8080
    codec => json
    tags => ["http_input"]
  }

  # Beats input (Filebeat)
  beats {
    port => 5044
    tags => ["beats_input"]
  }

  # TCP input for direct log shipping
  tcp {
    port => 5000
    codec => json_lines
    tags => ["tcp_input"]
  }

  # Syslog input
  syslog {
    port => 514
    tags => ["syslog_input"]
  }
}

filter {
  # Parse JSON logs from Python applications
  if [tags] and "json" in [tags] {
    json {
      source => "message"
    }
  }

  # Add timestamp if not present
  if ![timestamp] {
    mutate {
      add_field => { "timestamp" => "%{@timestamp}" }
    }
  }

  # Parse application logs
  if [logger_name] {
    mutate {
      add_field => { "log_type" => "application" }
    }
  }

  # Parse container logs
  if [container_name] {
    mutate {
      add_field => { "log_type" => "container" }
    }
  }

  # Parse trace information
  if [trace_id] {
    mutate {
      add_field => { "has_trace" => true }
    }
  }

  # Grok pattern for unstructured logs
  grok {
    match => { 
      "message" => "%{TIMESTAMP_ISO8601:log_timestamp} %{LOGLEVEL:log_level} %{DATA:log_message}" 
    }
    tag_on_failure => ["_grokparsefailure"]
  }

  # Convert log level to lowercase for consistency
  if [log_level] {
    mutate {
      lowercase => ["log_level"]
    }
  }

  # Add environment information
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:development}"
      "service" => "${SERVICE_NAME:devsecops}"
      "version" => "${SERVICE_VERSION:1.0.0}"
    }
  }

  # GeoIP enrichment for IP addresses
  if [remote_addr] and [remote_addr] !~ /^(10\.|192\.168\.|172\.(1[6-9]|2[0-9]|3[0-1])\.)/ {
    geoip {
      source => "remote_addr"
      target => "geoip"
    }
  }

  # Remove sensitive information
  mutate {
    remove_field => ["password", "secret", "token", "authorization"]
  }

  # Date parsing
  date {
    match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss.SSS" ]
    target => "@timestamp"
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
    index => "devsecops-logs-%{+YYYY.MM.dd}"

    # Index template
    template_name => "devsecops-logs"
    template_pattern => "devsecops-logs-*"
    template => {
      "index_patterns" => ["devsecops-logs-*"]
      "settings" => {
        "number_of_shards" => 1
        "number_of_replicas" => 0
        "index.refresh_interval" => "5s"
      }
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" }
          "trace_id" => { "type" => "keyword" }
          "span_id" => { "type" => "keyword" }
          "log_level" => { "type" => "keyword" }
          "logger_name" => { "type" => "keyword" }
          "service" => { "type" => "keyword" }
          "environment" => { "type" => "keyword" }
          "message" => { "type" => "text" }
          "method" => { "type" => "keyword" }
          "path" => { "type" => "keyword" }
          "status_code" => { "type" => "integer" }
          "duration_ms" => { "type" => "float" }
          "remote_addr" => { "type" => "ip" }
        }
      }
    }
  }

  # Debug output for development
  if "${DEBUG_OUTPUT:false}" == "true" {
    stdout {
      codec => rubydebug
    }
  }

  # Dead letter queue for failed documents
  if "_elasticsearch_error" in [tags] {
    file {
      path => "/var/log/logstash/failed_documents.log"
      codec => json_lines
    }
  }
}
